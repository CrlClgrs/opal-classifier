<h2 id="data_presentation">Data Presentation</h2>
<p>The questions are organized in a two-level structure, as illustrated in the following plot:
    <iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="./html/tag_hierarchy.html"
        height="525" width="100%"></iframe>
</p>

<p>The dataset contains over 7,000 questions distributed among the tags as shown here:
    <iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="./html/tag_counts.html"
        height="525" width="100%"></iframe>
</p>

<p>Each question has two tags, one for each level. Furthermore, every question has a true or false answer.
</p>

<blockquote> The primary objective is to build a classifier capable of predicting the correct categories for
    a given
    question.
</blockquote>

<h3 id="data_presentation_embed_text">Embed the Text</h3>
Each question was transformed into a numerical vector using an embedding model from the
<mark>Google GenAI</mark> suite, specifically the '<code>models/text-embedding-004</code>' <a href="#section1">[1]</a>

<pre><code class="language-python">
                # Example call to the embedding model
                embedding = google_ai_client.models.embed_content(
                    model=embedding_model, contents=text
                )
                # embedding_result typically contains the numerical vector
            </code></pre>

<p>
    The model converts the original question text into a vector of 768 numbers. <br>
    This vector serves as the ideal input for a neural network, while the network's output should represent
    the target categories.
</p>


<h3 id="data_presentation_encode_output">Encode the Output</h3>
<p>Given \(n\) possible categories, we considered two options for representing the target output:</p>
<ul>
    <li>Using a single floating-point number representing a category index (e.g., in the range \([1, n]\)).
    </li>
    <li>Using an \(n\)-element array where each element is in the range \([0, 1]\), representing the
        probability that the corresponding category is associated with the question.</li>
</ul>
<p> We chose the second option to better handle cases where a question might belong to multiple categories
    simultaneously. <br>
    We assigned a fixed order to all category tags. Since there are 30 tags in this example, the target
    output for each question is a 30-element vector. <br>
    Maintaining this predefined order is crucial to ensure each tag corresponds to a consistent position in
    the output vector.
</p>

<h3 id="data_presentation_network_setup">Setup the Network</h3>
<p>Therefore, for a single question, the network processes:</p>
<ul>
    <li>A 768-element input vector, representing the embedded text.</li>
    <li>A 30-element output vector, representing the target category associations.</li>
</ul>
<blockquote>We do not explicitly inform the network about the hierarchical structure of the tags; it is free
    to learn associations independently.</blockquote>
<p>
    The network predicts category associations by assigning a probability to each tag. A higher probability
    suggests the tag is more suitable for that question. In the training dataset, the target
    output vectors consist only of 0s (for unassociated tags) and 1s (for associated tags).
</p>

<p>This is a graphical representation of the network:
    <iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="./html/network.html" height="525"
        width="100%"></iframe>
</p>