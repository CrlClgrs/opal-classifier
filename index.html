<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yet Another NN Powered Classifier</title>
    <link rel="stylesheet" href="style.css">
    <script src='https://cdn.plot.ly/plotly-2.32.0.min.js'></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css"
        integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js"
        integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6"
        crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js"
        integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
</head>

<body>
    <div class="content-column">
        <header>
            <h1>Classifying Text</h1>
        </header>

        <article>
            <blockquote>What we are talking about.</blockquote>

            <div class="qa-box">
                <p><b>What is text classifying?</b><BR>
                    Text classification is the task of automatically assigning predefined labels or categories to pieces
                    of
                    text.</p>
                <p><b>Why is it important?</b><BR>
                    Text classification is important because it allows us to automatically make sense of and organize
                    large
                    volumes of text data, which would be impossible or incredibly time-consuming to do manually.</p>
                <p><b>Which techniques are commonly used?</b><BR>
                    Common methods range from traditional algorithms (like Naive Bayes, SVM) to deep learning (like
                    LSTMs or
                    Transformers/BERT).</p>
                <p><b>Why does this suit very well with ML and AI approach?</b><BR>
                    Because ML/AI excels at automatically learning complex patterns from text data to assign categories
                    accurately, handling the nuance and scale of language far better than manual rules.</p>
                <p><b>What is the base technique behind this approach?</b><BR>
                    The base technique is typically supervised machine learning. This means you train an algorithm using
                    a
                    large dataset of text examples that have already been manually assigned the correct category labels.
                    The
                    algorithm learns the patterns and relationships between the text features (words, embeddings, etc.)
                    and
                    the corresponding labels, enabling it to predict labels for new, unseen text.</p>
                <p><b>What is the embedding?</b><BR>
                    Essentially, an embedding is the numerical vector (a list of numbers) used to represent a piece of
                    text
                    for the machine learning model. It's designed so that texts with similar meanings result in vectors
                    that are mathematically close to each other.</p>
                <p><b>But how can I transform my text into an embedding?</b><BR>
                    You typically use a pre-trained AI model (accessed via an API or code library) to convert your text
                    into
                    its numerical embedding vector.
                </p>
                <p><b>How can this be profitable?</b><BR>
                    It's profitable by automating tasks (cutting costs) and extracting valuable insights from text data
                    to
                    improve customer experience, boost sales, and make smarter business decisions.
                </p>
                <p><b>What are some practical examples?</b><BR>
                    Email spam filtering,
                    customer support ticket routing,
                    sentiment analysis,
                    content moderation,
                    topic labelling,
                    intent recognition
                </p>
            </div>

            <blockquote>Given that, we now want to build an example of how text classifying could work. <BR>
                As our sample
                dataset, we will use the questions and answers (Q&As) from the Italian driving license
                examination </blockquote>

            <!--------------------------------------------------------------------------------------------------------->
            <!--------------------------------------------------------------------------------------------------------->
            <h2>Section 1: Data Presentation</h2>
            <p>The questions are organized in a two-level structure, as illustrated in the following plot:
                <iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="tag_hierarchy.html"
                    height="525" width="100%"></iframe>
            </p>

            <p>The dataset contains over 7,000 questions distributed among the tags as shown here:
                <iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="tag_counts.html"
                    height="525" width="100%"></iframe>
            </p>

            <p>Each question has two tags, one for each level. Furthermore, every question has a true or false answer.
            </p>

            <blockquote> The primary objective is to build a classifier capable of predicting the correct categories for
                a given
                question.
            </blockquote>

            <!--------------------------------------------------------------------------------------------------------->
            <!--------------------------------------------------------------------------------------------------------->
            <h2>Section 2: The Approach</h2>
            <h3>Section 2.1: Embed the Text</h3>
            Each question was transformed into a numerical vector using an embedding model from the
            <mark>Google GenAI</mark> suite, specifically the '<code>models/text-embedding-004</code>' <a
                href="#section1">[1]</a>

            <pre><code class="language-python">
                # Example call to the embedding model
                embedding = google_ai_client.models.embed_content(
                    model=embedding_model, contents=text
                )
                # embedding_result typically contains the numerical vector
            </code></pre>

            <p>
                The model converts the original question text into a vector of 768 numbers. <br>
                This vector serves as the ideal input for a neural network, while the network's output should represent
                the target categories.
            </p>

            <!--------------------------------------------------------------------------------------------------------->
            <!--------------------------------------------------------------------------------------------------------->
            <h3>Section 2.2: Encode the Output</h3>
            <p>Given \(n\) possible categories, we considered two options for representing the target output:</p>
            <ul>
                <li>Using a single floating-point number representing a category index (e.g., in the range \([1, n]\)).
                </li>
                <li>Using an \(n\)-element array where each element is in the range \([0, 1]\), representing the
                    probability that the corresponding category is associated with the question.</li>
            </ul>
            <p> We chose the second option to better handle cases where a question might belong to multiple categories
                simultaneously. <br>
                We assigned a fixed order to all category tags. Since there are 30 tags in this example, the target
                output for each question is a 30-element vector. <br>
                Maintaining this predefined order is crucial to ensure each tag corresponds to a consistent position in
                the output vector.
            </p>

            <h3>Section 2.3: Setup the Network</h3>
            <p>Therefore, for a single question, the network processes:</p>
            <ul>
                <li>A 768-element input vector, representing the embedded text.</li>
                <li>A 30-element output vector, representing the target category associations.</li>
            </ul>
            <blockquote>We do not explicitly inform the network about the hierarchical structure of the tags; it is free
                to learn associations independently.</blockquote>
            <p>
                The network predicts category associations by assigning a probability to each tag. A higher probability
                suggests the tag is more suitable for that question. In the training dataset, the target
                output vectors consist only of 0s (for unassociated tags) and 1s (for associated tags).
            </p>

            <p>This is a graphical representation of the network:
                <iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="network.html"
                    height="525" width="100%"></iframe>
            </p>

            <!--------------------------------------------------------------------------------------------------------->
            <!--------------------------------------------------------------------------------------------------------->
            <h2>Section 3: The Result</h2>
            <p>The result is usually presented in the form of a confusion matrix:
                <iframe id="igraph" scrolling="no" style="border:none;display:block" seamless="seamless"
                    src="confusion_matrix_MulticlassModel01_FULL_SET.html" height="900px" width="100%"></iframe>
            </p>
            <p>In this heatmap, we analyze the model's predictions, showing the average predicted probability for each
                tag category, likely correlated with the true categories.
                It's evident that the main tag categories are typically assigned high probabilities by the model,
                whereas some secondary categories present more of a challenge, receiving lower average probabilities.
            </p>
            <p>Overall, the results are encouraging. The primary tag (level 1) predictions are highly accurate (as seen
                by the blue vertical lines), while the secondary tag (level 2) predictions are less distinct. However,
                even when the secondary tag prediction is incorrect, it often falls within the expected category group.
            </p>
            <p>Further investigation into the specific prediction errors could be insightful.</p>
            <blockquote>Such a deep dive might
                reveal patterns in the model's mistakes or even suggest potential ambiguities or inaccuracies in the
                original tagging of the questions.</blockquote>
            <p>These are the confusion counts:
                <iframe id="igraph" scrolling="no" style="border:none;display:block" seamless="seamless"
                    src="error_heatmapMulticlassModel01_FULL_SET.html" height="800px" width="100%"></iframe>
            </p>
            <p>This plot analyzes the model's predictions by considering the top two most likely tags assigned to each
                question.</p>
            <p>It clearly shows that prediction errors are relatively infrequent, and most of them are concentrated
                within the central part of the visualization. This central region corresponds to questions covering very
                similar topics, which makes some level of confusion understandable.</p>
            <p>Other areas prone to errors involve questions about traffic and those concerning the vehicle itself. For
                these topics, the original tagging may be inherently ambiguous or difficult to assign definitively,
                likely contributing to the model's confusion.</p>

            <!--------------------------------------------------------------------------------------------------------->
            <!--------------------------------------------------------------------------------------------------------->
            <h2>Section 4: The Embedding</h2>
            <blockquote>While the neural network performs the classification task, the real magic often lies in the
                embeddings
                themselves.</blockquote>
            <p>An embedding represents items (like words or sentences, in our case) as numerical vectors&mdash;lists of
                numbers. The key idea is that these vectors capture semantic meaning, so items with similar meanings are
                represented by vectors close together in the high-dimensional space. This numerical format allows
                machine learning models, like neural networks, to understand and process complex data such as text.</p>
            <p>We wanted to gain a visual intuition for how these embeddings are structured. Since they are
                high-dimensional vectors (768 dimensions in this work), we need specific techniques to represent them
                visually in two or three dimensions. For this purpose, we explored dimensionality reduction techniques,
                initially focusing on PCA and t-SNE <a href="#section1">[2]</a>.</p>
            <p>Both PCA (Principal Component Analysis) and t-SNE (t-Distributed Stochastic Neighbor Embedding) serve
                this function. They are used here to take these high-dimensional embedding vectors (which, with 768
                dimensions, are impossible to plot directly) and project them into a low-dimensional space.</p>
            <p>The underlying assumption is that embeddings for semantically similar concepts will cluster together
                within the high-dimensional space.</p>

            <p>These are the plots of the embeddings reduced with PCA:
                <iframe id="igraph" scrolling="no" style="border:none;display:block" seamless="seamless"
                    src="embedding_pca_2.html" height="400px" width="100%"></iframe>
                <iframe id="igraph" scrolling="no" style="border:none;display:block" seamless="seamless"
                    src="embedding_pca_3.html" height="700px" width="100%"></iframe>
            </p>
            <p>while these are the plots of the embeddings reduced with t-SNE:
                <iframe id="igraph" scrolling="no" style="border:none;display:block" seamless="seamless"
                    src="embedding_tsne_2.html" height="400px" width="100%"></iframe>
                <iframe id="igraph" scrolling="no" style="border:none;display:block" seamless="seamless"
                    src="embedding_tsne_3.html" height="700px" width="100%"></iframe>
            </p>
            <p>By visualizing these embeddings we can more easily perceive which tag categories are related (appearing
                nearby in the plot with relative colors) and identify categories that the classification model may
                frequently confuse with
                one another (indicated by overlapping or indistinct clusters).</p>

            <!--------------------------------------------------------------------------------------------------------->
            <!--------------------------------------------------------------------------------------------------------->
            <h2>Section 5: The Clusters</h2>
            <blockquote>But if we know the embedding vectors why not trying to build a classifcation possibly better
                than the one initially provided? </blockquote>
            <p>The semantics and the concept relationships are somehow stored in the embedding vectors:
                so we can use them as an input for 'traditional' clusterization techniques in order to find a
                classification by ourselves.</p>


            <!--------------------------------------------------------------------------------------------------------->
            <!--------------------------------------------------------------------------------------------------------->
            <HR>
            <note>[1] <a
                    href="https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings">Embeddings
                    Docs on Google Generative AI</a></note>

            <BR>

            <note>[2] PCA rotates your data so the maximum variance lies along the first new axis (PC1), the maximum
                remaining variance lies along the second axis (PC2, perpendicular to PC1), and so on. To visualize in
                2D, it projects your 768-dimensional points onto the first two principal components (PC1 and PC2),
                discarding the other dimensions.
                t-SNE focuses on preserving the local structure. It calculates a measure of similarity between pairs of
                points in the high-dimensional space (nearby points are considered similar). It then tries to arrange
                the points in the low-dimensional (2D) map so that similar high-dimensional points are close together
                and dissimilar points are far apart. It uses probabilities and an optimization process to achieve this
                arrangement.
            </note>



        </article>

        <footer>
            <p>&copy; 2025 Opal Company</p>
        </footer>
</body>

</html>